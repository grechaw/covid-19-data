This is more about notes, but also about collecting some best practices.


The premise is that the goal of my project is to have an artifact that I can move
from a development environment to a test environment.  I believe that,
through the construction of a reference graphmart, one can tailor the export service
to include everything needed for this kind of project.
tas



The goal of a project is to have a refrence implementation of graphmarts that unambiguously defines the whole dependency graph.
Correlary- any other graphmarts in an engagement should not have dependencies that are models/pipelines




Add new file.

Went and found file with land area in it

download and process with in2csv
census LND01

Find data sources, census
Add file
Import
Add to dictionary
Navigates to dictionary, that's good
No idea what this is all for though...

i tried splitting, did what i wanted i think...

now ingest using dictionary?
go back to data sources, do dance to ingest with data dictionary

navigate to pipelines, find it
made a new one because id renamed schema/data source
and only the LND job is in it.  crep

so the old one census pop is still there
this gets so messy
annnd... it doesn't run.

try deleting pipeline...

now the whole thing is fucked.



try -- changing a type in your model

----
Pristine script first

a. add two census files
b. add just the columns with values to a new data dictionary
c. add covid, full select all tables
d. add to existing dictionary

e. ingest census with dictionary, create new model
f. ingest covid with dictionary, add to model -- no option to add to existing model
    used same ontology URI as previous step, which caused:
    g. run pipeline one failed.
h. run pipeline 2 succeeded.

models -- what was the point of just selecting specific columns if the whole chunker is coming in anyway.
there's no simple way to make a canonical model without writing the whole chunker into data layers

ugh, merging seemed promising but i get an untitled class.




(create gqe store, import azg.trig that is pre-existing)

import version what the hell does that do -- you can navigate to a zip but there was no change in version tab after impot

A few times now I’ve tried to build groud-up demos, right now of course with covid data.  And what occurs to me today is that, even from a narrative of how one might want to approach a very simple integration, Anzo makes you think and hold a lot of knowledge outside the tool in order to make the right decisions when using it.  I find myself iterating over a very basic scripting method — a bare repo with some config that I import and try to repeat the process or build on it incrementally.
It seems that even the user stories for Anzo don’t really take into account a whole arc.  The only user story I’d be able to construct is one that is micro-focused on one particular component, without the context of how it fits.
I understand it’s always a moving target, just trying to understand better why it frustrates me.




